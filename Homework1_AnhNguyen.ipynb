{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Replication the regression table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/anhnguyen/Documents/GitHub/2025AAE722_AnhNguyen'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     TV  radio  newspaper  sales\n",
      "0           1  230.1   37.8       69.2   22.1\n",
      "1           2   44.5   39.3       45.1   10.4\n",
      "2           3   17.2   45.9       69.3    9.3\n",
      "3           4  151.5   41.3       58.5   18.5\n",
      "4           5  180.8   10.8       58.4   12.9\n",
      "Number of rows: 200, Number of columns: 5\n",
      "Column names: ['Unnamed: 0', 'TV', 'radio', 'newspaper', 'sales']\n",
      "Data types:\n",
      "Unnamed: 0      int64\n",
      "TV            float64\n",
      "radio         float64\n",
      "newspaper     float64\n",
      "sales         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "df = pd.read_csv('Advertising.csv')  # replace with your file path\n",
    "print(df.head())\n",
    "\n",
    "# Count the number of rows and columns\n",
    "num_rows, num_cols = df.shape\n",
    "print(f'Number of rows: {num_rows}, Number of columns: {num_cols}')\n",
    "# List all column names\n",
    "print(f'Column names: {df.columns.tolist()}')\n",
    "# Display data types of each column\n",
    "print(f'Data types:\\n{df.dtypes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  sales   R-squared:                       0.897\n",
      "Model:                            OLS   Adj. R-squared:                  0.896\n",
      "Method:                 Least Squares   F-statistic:                     570.3\n",
      "Date:                Sat, 20 Sep 2025   Prob (F-statistic):           1.58e-96\n",
      "Time:                        22:43:17   Log-Likelihood:                -386.18\n",
      "No. Observations:                 200   AIC:                             780.4\n",
      "Df Residuals:                     196   BIC:                             793.6\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.9389      0.312      9.422      0.000       2.324       3.554\n",
      "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
      "radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
      "newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
      "==============================================================================\n",
      "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
      "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
      "Kurtosis:                       6.332   Cond. No.                         454.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Fit a multiple linear regression of sales on TV, radio, newspaper\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# use existing dataframe `df`\n",
    "X = df[['TV', 'radio', 'newspaper']]\n",
    "y = df['sales']\n",
    "\n",
    "# 1) Statsmodels OLS (full summary)\n",
    "X_const = sm.add_constant(X)\n",
    "ols_model = sm.OLS(y, X_const).fit()\n",
    "print(ols_model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Hypothese "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. \n",
    "\n",
    "Null Hypothesis (H0): There is no relationship between TV advertising and Sales.\n",
    "   \n",
    "    H0: Beta1 = 0\n",
    "\n",
    "If Beta1=0, the estimated regression model reduces to: ' estiamted Sales' = 2.939 + 0.189 X Radio - 0.001 X Newspaper, meaning TV does not contribute to explaining Sales.\n",
    "    \n",
    "Alternative Hypothesis (HA): There is a relationship between TV advertising and Sales.\n",
    "    \n",
    "    H0: Beta1 != 0\n",
    "\n",
    "b. \n",
    "\n",
    "Null Hypothesis (H0): There is no relationship between Radio advertising and Sales.\n",
    "   \n",
    "    H0: Beta2 = 0\n",
    "\n",
    "If Beta2=0, the estimated regression model reduces to: ' estiamted Sales' = 2.939 + 0.046 X TV - 0.001 X Newspaper, meaning Radio does not contribute to explaining Sales.\n",
    "    \n",
    "Alternative Hypothesis (HA): There is a relationship between Radio advertising and Sales.\n",
    "    \n",
    "    H0: Beta2 != 0\n",
    "\n",
    "c. \n",
    "\n",
    "Null Hypothesis (H0): There is no relationship between Newspaper advertising and Sales.\n",
    "   \n",
    "    H0: Beta3 = 0\n",
    "\n",
    "If Beta3=0, the estimated regression model reduces to: ' estiamted Sales' = 2.939 + 0.046 X TV + 0.189 X Radio, meaning Newspaper does not contribute to explaining Sales.\n",
    "    \n",
    "Alternative Hypothesis (HA): There is a relationship between Newspaper advertising and Sales.\n",
    "    \n",
    "    H0: Beta3 != 0\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Interpreting the results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Overall model is statistically significant (F-test p = 1.58e-96). At least one of the predictors in the model explains variation in sales (the dependent variable).\n",
    "\n",
    "\n",
    "b. TV: coef = 0.046, p = 1.51e-81 -> statistically significant at 5%.\n",
    "Interpretation: a one-unit increase in TV is associated with an average 0.046 change in sales (holding other predictors constant).\n",
    "\n",
    "\n",
    "c. Radio: coef = 0.189, p = 1.51e-54 -> statistically significant at 5%. \n",
    "Interpretation: a one-unit increase in radio is associated with an average 0.189 change in sales (holding other predictors constant).\n",
    "\n",
    "\n",
    "d. Newspaper: coef = -0.001, p = 0.86 -> not statistically significant at 5%. Interpretation: no strong evidence that newspaper affects sales once other predictors are controlled for.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts\n",
    "\n",
    "a. K-Nearest Neighbors (KNN):\n",
    "\n",
    "KNN is a non-parametric, instance-based learning method. Instead of assuming a functional form, KNN uses the proximity of data points in feature space to make predictions.\n",
    "\n",
    "Some common distance metrics are Euclidean, Manhattan, Minkowski, or cosine similarity.\n",
    "\n",
    "b. KNN Classifier:\n",
    "\n",
    "KNN Classifier helps to predict a categorial label.\n",
    "\n",
    "We choose a value of K (the number of neighbors to consider). After KNN Classifier calculates the distance from a new observation to all training points, it will identify the K nearest neighbors and take a majority vote to classify the new observation to the class most common among the K neighbors.\n",
    "\n",
    "c. KNN Regression:\n",
    "\n",
    "KNN Regression helps to predict a continuous numeric value. \n",
    "\n",
    "We choose a value of K. KNN Regression finds its K nearest neighbors after calculating the distance from a new observatin to all training points. The outcome is the weighted average of the target values. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences\n",
    "\n",
    "a. Outputs for KNN Classifier is discrete labels while KNN Regression's outputs are the continuous.\n",
    "\n",
    "b. Decision rule for KNN Classifier is the majority voting among neighbors, while KNN Regression's decision is based on average or weighted avearage of neighbors. \n",
    "\n",
    "c. KNN Classifier evaluates models based on accuracy, precision, recall, and F1 score metrics. KNN Regression evaluates models based on R-squared, RMSE, MAE.\n",
    "\n",
    "d. Loss fucntions (how wrong a model's prediction is) for KNN Classifier are classification error and cross-entropy. Loss functions for KNN Regression are mean squared error (MSE), mean absolute error (MAE).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Training RSS - Linear true relationship\n",
    "\n",
    "The cublic model training's residual sum of squares (RSS) will be lower than the linear model training's.\n",
    "\n",
    "This is because the linear model is nested inside the cubic model. The cubic model is more flexible, fits more noise, thus achieves a lower training RSS. \n",
    "\n",
    "## (b) Test RSS - Linear true relationship\n",
    "\n",
    "The linear model will have a lower expected test RSS when the true relationship is linear. \n",
    "\n",
    "This is because of bias-variance tradeoff issue. The linear model is correctly specified, achieving lower/zero bias and lower variance. The cubic model is more flexible, thus increasing variance without reducing bias and overfitting the training noise, making cubic model generalize worse than the linear model. \n",
    "\n",
    "## (c) Training RSS - Non-linear true relationship\n",
    "\n",
    "The cubmic model training's RSS will be lower than the linear model training's. \n",
    "\n",
    "This is because the linear model is nested inside the cublic model. In OLS, adding regressors cannot increase in-sample fit. Adding regressors into an OLS function is usually stricter unless the related coefficients land exactly at 0. \n",
    "\n",
    "## (d) Test RSS - Non-linear true relationship\n",
    "\n",
    "There is not enough information to tell which model has lower RSS. \n",
    "\n",
    "With a nonlinear true relationship, the cubic can reduce bias relative to the linear, but it also adds variance (two extra parameters) and may still be misspecified if the true function isn’t well-approximated by a cubic. Which effect dominates depends on: (1) how nonlinear the truth is, (2) noise level, (3) sample size, (4) the predictor's distribution.\n",
    "\n",
    "In this case, it is practical to use cross-validation test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Generate reproducible data\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = 2 * x + rng.normal(size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) Y onto X regression (without an intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.743\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.740\n",
      "Method:                 Least Squares   F-statistic:                              285.6\n",
      "Date:                Sun, 21 Sep 2025   Prob (F-statistic):                    6.23e-31\n",
      "Time:                        12:36:33   Log-Likelihood:                         -141.35\n",
      "No. Observations:                 100   AIC:                                      284.7\n",
      "Df Residuals:                      99   BIC:                                      287.3\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.9762      0.117     16.898      0.000       1.744       2.208\n",
      "==============================================================================\n",
      "Omnibus:                        1.376   Durbin-Watson:                   2.184\n",
      "Prob(Omnibus):                  0.503   Jarque-Bera (JB):                0.847\n",
      "Skew:                           0.121   Prob(JB):                        0.655\n",
      "Kurtosis:                       3.381   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Fit OLS without an intercept\n",
    "\n",
    "# reshape x to 2D (n x 1)\n",
    "x = x.reshape(-1, 1)\n",
    "\n",
    "# Fit OLS without intercept\n",
    "model_no_intercept = sm.OLS(y, x).fit()\n",
    "\n",
    "beta = model_no_intercept.params[0]\n",
    "se = model_no_intercept.bse[0]\n",
    "tstat = model_no_intercept.tvalues[0]\n",
    "pval = model_no_intercept.pvalues[0]\n",
    "\n",
    "print(model_no_intercept.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "(a) The coefficient estimate is very close to the true value of 2 used in the data-generating process.\n",
    "\n",
    "(b) The standard error is small, indicating a precise estimate.\n",
    "\n",
    "(c) The t-statistic tests the null hypothesis that the coefficient is zero. The t-statistic is large in magnitude, suggesting we can reject the null hypothesis.\n",
    "\n",
    "(d) The p-value indicates the significance of the coefficient. The p-value is very small, suggesting strong evidence against the null hypothesis.\n",
    "    \n",
    "(e) The R-squared value indicates that a large proportion of the variance in Y is explained by X.\n",
    "    \n",
    "Overall, the results suggest a strong positive relationship between X and Y, consistent with the data-generating process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) X onto Y regression (without an intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.743\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.740\n",
      "Method:                 Least Squares   F-statistic:                              285.6\n",
      "Date:                Sun, 21 Sep 2025   Prob (F-statistic):                    6.23e-31\n",
      "Time:                        12:50:41   Log-Likelihood:                         -58.349\n",
      "No. Observations:                 100   AIC:                                      118.7\n",
      "Df Residuals:                      99   BIC:                                      121.3\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.3757      0.022     16.898      0.000       0.332       0.420\n",
      "==============================================================================\n",
      "Omnibus:                       13.156   Durbin-Watson:                   2.034\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               22.596\n",
      "Skew:                          -0.528   Prob(JB):                     1.24e-05\n",
      "Kurtosis:                       5.075   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "x = x.reshape(-1, 1)   # predictor must be 2D\n",
    "model_xy = sm.OLS(x, y).fit()   # x ~ β*y, no intercept\n",
    "\n",
    "beta_xy = model_xy.params[0]\n",
    "se_xy   = model_xy.bse[0]\n",
    "tstat_xy= model_xy.tvalues[0]\n",
    "pval_xy = model_xy.pvalues[0]\n",
    "\n",
    "print(model_xy.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "(a) The coefficient estimate is 0.4, close to the true value of 1/2 (or 0.5) used in the data-generating process.\n",
    "\n",
    "(b) The standard error is small, indicating a precise estimate.\n",
    "\n",
    "(c) The t-statistic tests the null hypothesis that the coefficient is zero. The t-statistic is 16.89, suggesting we can reject the null hypothesis.\n",
    "\n",
    "(d) The p-value indicates the significance of the coefficient. The p-value is verry small, suggesting strong evidence against the null hypothesis.\n",
    "    \n",
    "(e) The R-squared value indicates that a large proportion of the variance in X is explained by Y.\n",
    "    \n",
    "Overall, the results suggest a strong positive relationship between Y and X. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Relationship between (a) and (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The goodness of fit is idential in both models since the R-squared (or adjusted R-squared) and t-stat values are the same.\n",
    "\n",
    "        ==> The strength of relationship is symmetric. Both regression capture the same underlying strong linear association since they are based on the same correlation.\n",
    "\n",
    "2. The slope in (a) is 1.976 while the slope in (b) is 0.376. These slopes are not reciprocals. This is becasue each regression optimizes a differen criterion, so the line of best fit is different depending on which variable are treated as the dependent variable. In another word, regressing Y on X minimizes vertical errors in Y, while regression X on Y minizing verical error in X.\n",
    "\n",
    "        ==> Slopes are asymmetric because one is scaled in units of Y per X and the other is in units of X per Y.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) Formula Proof\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta-hat:            1.9762423774420508\n",
      "SE(beta-hat):        0.11694837274226332\n",
      "t (direct formula):  16.898417063035094\n",
      "t (identity form):   16.898417063035094\n",
      "Difference:          0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Generate reproducible data\n",
    "rng = np.random.default_rng(1)\n",
    "x = rng.normal(size=100)\n",
    "y = 2 * x + rng.normal(size=100)\n",
    "\n",
    "n = len(x)\n",
    "\n",
    "# 2. Compute the core sums\n",
    "Sxy = np.sum(x * y)     # sum of cross-products\n",
    "Sxx = np.sum(x**2)      # sum of squares of x\n",
    "Syy = np.sum(y**2)      # sum of squares of y\n",
    "\n",
    "# 3. Compute beta-hat and standard error (no intercept case)\n",
    "beta_hat = Sxy / Sxx\n",
    "RSE = Syy - (Sxy**2) / Sxx\n",
    "SE_beta = np.sqrt(RSE / ((n - 1) * Sxx))\n",
    "\n",
    "t_direct = beta_hat / SE_beta   # definition\n",
    "\n",
    "# 4. Alternative identity form for t-stat\n",
    "t_identity = np.sqrt(n - 1) * Sxy / np.sqrt(Sxx * Syy - Sxy**2)\n",
    "\n",
    "# 5. Print both to confirm equality\n",
    "print(\"Beta-hat:           \", beta_hat)\n",
    "print(\"SE(beta-hat):       \", SE_beta)\n",
    "print(\"t (direct formula): \", t_direct)\n",
    "print(\"t (identity form):  \", t_identity)\n",
    "print(\"Difference:         \", t_direct - t_identity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
